{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3edb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use two packages to open Excel files\n",
    "#!pip install xlrd --break-system-packages\n",
    "\n",
    "#!pip install openpyxl --break-system-packages\n",
    "\n",
    "# Install the disambiguation package (no need for a master list of firm names)\n",
    "#pip install disamby --break-system-packages\n",
    "#!pip install rapidfuzz\n",
    "\n",
    "# Load package for data manipulation purposes\n",
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad315306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in June 2015 data to make a complete set of data; get rid of associations that list condo in name and those with zero listed units\n",
    "\n",
    "june15_df = pd.read_excel(\"../Data/NRED/2015/NRED HOA - 06 2015.xls\")\n",
    "\n",
    "june15_df = june15_df[~june15_df['Name'].str.contains('condo', case=False, na=False)]\n",
    "june15_df = june15_df[~(june15_df['# of Units'] == 0)]\n",
    "\n",
    "june15_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca298f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a subset of observations that have management companies associated with them \n",
    "# Then sort in ascending alphabetical order according to the management company names\n",
    "june15_subset = june15_df[june15_df['Address1'].str.contains('C/O', na=False)].sort_values(by='Address1')\n",
    "june15_subset['City'] = june15_subset['City'].str.title()\n",
    "june15_subset['Address1'] = june15_subset['Address1'].str.replace(r'\\bC/O\\b', '', regex=True).str.title()\n",
    "june15_subset['Address2'] = june15_subset['Address2'].str.title()\n",
    "june15_subset['Name'] = june15_subset['Name'].str.title()\n",
    "\n",
    "june15_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and rename common entries that are unique in name and by listed phone number\n",
    "# Proactively clean so that firms are \"umbrella-ed\" with multiple addresses and phone numbers under them\n",
    "\n",
    "def singularize_word(word):\n",
    "    if len(word) > 3 and word.endswith('s') and not word.endswith('ss'):\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "def normalize_address(address):\n",
    "    if pd.isnull(address):\n",
    "        return ''\n",
    "    address = address.lower()\n",
    "    \n",
    "    # Normalize common road types\n",
    "    address = re.sub(r'\\b(streets|street|st)\\b', 'st', address)\n",
    "    address = re.sub(r'\\b(roads|road|rd)\\b', 'rd', address)\n",
    "    address = re.sub(r'\\b(avenues|avenue|ave)\\b', 'ave', address)\n",
    "    address = re.sub(r'\\b(boulevards|boulevard|blvd)\\b', 'blvd', address)\n",
    "    address = re.sub(r'\\b(suites|suite|ste|se)\\b', 'ste', address) \n",
    "    address = re.sub(r'\\b(apartments|apartment|apt)\\b', 'apt', address)\n",
    "    address = re.sub(r'\\b(forts|fort|ft)\\b', 'ft', address)\n",
    "    \n",
    "    # Standardize street directions\n",
    "    address = re.sub(r'\\b(south|s)\\b', 's', address)\n",
    "    address = re.sub(r'\\b(north|n)\\b', 'n', address)\n",
    "    address = re.sub(r'\\b(east|e)\\b', 'e', address)\n",
    "    address = re.sub(r'\\b(west|w)\\b', 'w', address)\n",
    "    address = re.sub(r'\\b(southeast|se)\\b', 'se', address)\n",
    "    address = re.sub(r'\\b(northeast|ne)\\b', 'ne', address)\n",
    "    address = re.sub(r'\\b(southwest|sw)\\b', 'sw', address)\n",
    "    address = re.sub(r'\\b(northwest|w)\\b', 'nw', address)\n",
    "    \n",
    "    # Eliminate firm office indicators\n",
    "    address = re.split(r'\\b(suite|ste|apt|apartment|unit|site)\\b', address)[0]\n",
    "    \n",
    "    # Remove punctuation and number sign\n",
    "    address = re.sub(r'[.,]', '', address)\n",
    "    address = re.sub(r'\\s+', ' ', address).strip()\n",
    "    address = re.sub(r'#', '', address)\n",
    "\n",
    "    # Singularize words\n",
    "    address = ' '.join(singularize_word(word) for word in address.split())\n",
    "\n",
    "    return address\n",
    "\n",
    "def normalize_firm_name(name):\n",
    "    if pd.isnull(name):\n",
    "        return ''\n",
    "    name = name.lower().strip()\n",
    "    \n",
    "    # Take off suffixes\n",
    "    name = re.sub(r'\\b(llc|inc|corp|co|ltd)\\b', '', name)\n",
    "    \n",
    "    # Take off commas etc.\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)\n",
    "    \n",
    "    # Remove spaces\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    \n",
    "    #Singularize\n",
    "    name = ' '.join(singularize_word(word) for word in name.split())\n",
    "    \n",
    "    return name\n",
    "\n",
    "def normalize_phone(phone):\n",
    "    if pd.isnull(phone):\n",
    "        return ''\n",
    "    phone = re.sub(r'\\D', '', str(phone)) \n",
    "    return phone\n",
    "\n",
    "def get_mode(series):\n",
    "    mode = series.mode()\n",
    "    return mode.iloc[0] if not mode.empty else series.iloc[0]\n",
    "\n",
    "# Normalize all of the needed fields\n",
    "june15_subset['Address2_Normalized'] = june15_subset['Address2'].apply(normalize_address)\n",
    "june15_subset['Firm_Normalized'] = june15_subset['Address1'].apply(normalize_firm_name)\n",
    "june15_subset['Phone_Normalized'] = june15_subset['Telephone'].apply(normalize_phone)\n",
    "\n",
    "# Detect duplicates with two separate keys\n",
    "june15_subset['Phone_Key'] = june15_subset['Phone_Normalized']\n",
    "june15_subset['Address_Key'] = june15_subset['Address2_Normalized']\n",
    "\n",
    "# Canonical firm info\n",
    "canonical_phone = (\n",
    "    june15_subset.groupby('Phone_Key')\n",
    "    .agg({'Firm_Normalized': get_mode})\n",
    "    .rename(columns={'Firm_Normalized':'Firm_ByPhone'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "canonical_address = (\n",
    "    june15_subset.groupby('Address_Key')\n",
    "    .agg({'Firm_Normalized': get_mode})\n",
    "    .rename(columns={'Firm_Normalized':'Firm_ByAddress'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "june15_subset = june15_subset.merge(canonical_phone, on='Phone_Key', how='left')\n",
    "june15_subset = june15_subset.merge(canonical_address, on='Address_Key', how='left')\n",
    "\n",
    "def pick_canonical(row): # I NEED TO UNDERSTAND WHAT IS GOING ON HERE\n",
    "    if pd.notnull(row['Firm_ByPhone']):\n",
    "        return row['Firm_ByPhone']\n",
    "    elif pd.notnull(row['Firm_ByAddress']):\n",
    "        return row['Firm_ByAddress']\n",
    "    else:\n",
    "        return row['Firm_Normalized']\n",
    "\n",
    "june15_subset['Firm_Final'] = june15_subset.apply(pick_canonical, axis=1)\n",
    "\n",
    "# Additional fuzzy matching to fix edge cases\n",
    "unique_names = june15_subset['Firm_Final'].dropna().unique()\n",
    "name_map = {}\n",
    "\n",
    "for name in unique_names:\n",
    "    if name in name_map:  \n",
    "        continue\n",
    "    matches = process.extract(name, unique_names, scorer=fuzz.token_set_ratio, limit=None)\n",
    "    close_matches = [m[0] for m in matches if m[1] >= 80]  # PLAY AROUND WITH THRESHOLD\n",
    "    for cm in close_matches:\n",
    "        name_map[cm] = name  \n",
    "        \n",
    "june15_subset['Firm_Final'] = june15_subset['Firm_Final'].map(name_map).fillna(june15_subset['Firm_Final'])\n",
    "\n",
    "june15_subset.to_csv('../Data/Cleaned files/june15_subset.csv', index = False)\n",
    "\n",
    "june15_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in June 2025 data to make a complete set of data; get rid of associations that list condo in name and zero units cases\n",
    "\n",
    "june25_df = pd.read_excel(\"../Data/NRED/2025/NRED HOA - 06 2025.xlsx\")\n",
    "june25_df = june25_df[~june25_df['Name'].str.contains('condo', case=False, na=False)]\n",
    "june25_df = june25_df[~(june25_df['# of Units'] == 0)]\n",
    "\n",
    "june25_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16588f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another subset\n",
    "june25_subset = june25_df[june25_df['Address1'].str.contains('C/O', na=False)].sort_values(by='Address1')\n",
    "june25_subset['City'] = june25_subset['City'].str.title()\n",
    "june25_subset['Address1'] = june25_subset['Address1'].str.replace(r'\\bC/O\\b', '', regex=True).str.title()\n",
    "june25_subset['Address2'] = june25_subset['Address2'].str.title()\n",
    "june25_subset['Name'] = june25_subset['Name'].str.title()\n",
    "\n",
    "june25_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04af5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process\n",
    "\n",
    "june25_subset['Address2_Normalized'] = june25_subset['Address2'].apply(normalize_address)\n",
    "june25_subset['Firm_Normalized'] = june25_subset['Address1'].apply(normalize_firm_name)\n",
    "june25_subset['Phone_Normalized'] = june25_subset['Telephone'].apply(normalize_phone)\n",
    "\n",
    "june25_subset['Phone_Key'] = june25_subset['Phone_Normalized']\n",
    "june25_subset['Address_Key'] = june25_subset['Address2_Normalized']\n",
    "\n",
    "canonical_phone = (\n",
    "    june25_subset.groupby('Phone_Key')\n",
    "    .agg({'Firm_Normalized': get_mode})\n",
    "    .rename(columns={'Firm_Normalized':'Firm_ByPhone'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "canonical_address = (\n",
    "    june25_subset.groupby('Address_Key')\n",
    "    .agg({'Firm_Normalized': get_mode})\n",
    "    .rename(columns={'Firm_Normalized':'Firm_ByAddress'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "june25_subset = june25_subset.merge(canonical_phone, on='Phone_Key', how='left')\n",
    "june25_subset = june25_subset.merge(canonical_address, on='Address_Key', how='left')\n",
    "\n",
    "june25_subset['Firm_Final'] = june25_subset.apply(pick_canonical, axis=1)\n",
    "\n",
    "unique_names = june25_subset['Firm_Final'].dropna().unique()\n",
    "name_map = {}\n",
    "\n",
    "for name in unique_names:\n",
    "    if name in name_map:  \n",
    "        continue\n",
    "    matches = process.extract(name, unique_names, scorer=fuzz.token_set_ratio, limit=None)\n",
    "    close_matches = [m[0] for m in matches if m[1] >= 80]  \n",
    "    for cm in close_matches:\n",
    "        name_map[cm] = name  \n",
    "        \n",
    "june25_subset['Firm_Final'] = june25_subset['Firm_Final'].map(name_map).fillna(june25_subset['Firm_Final'])\n",
    "\n",
    "june25_subset.to_csv('../Data/Cleaned files/june25_subset.csv', index = False)\n",
    "\n",
    "june25_subset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
