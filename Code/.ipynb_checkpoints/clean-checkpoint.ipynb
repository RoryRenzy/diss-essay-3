{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3edb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use two packages to open Excel files\n",
    "#!pip install xlrd --break-system-packages\n",
    "\n",
    "!pip install openpyxl --break-system-packages\n",
    "\n",
    "# Install the disambiguation package (no need for a master list of firm names)\n",
    "#pip install disamby --break-system-packages\n",
    "!pip install rapidfuzz\n",
    "\n",
    "# Load package for data manipulation purposes\n",
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz, process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad315306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in June 2015 data to make a complete set of data; get rid of associations that list condo in name and those with zero listed units\n",
    "\n",
    "june15_df = pd.read_excel(\"../Data/NRED/2015/NRED HOA - 06 2015.xls\")\n",
    "june15_df = june15_df[~june15_df['Name'].str.contains('condo', case=False, na=False)]\n",
    "june15_df = june15_df[~(june15_df['# of Units'] == 0)]\n",
    "\n",
    "june15_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca298f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a subset of observations that have management companies associated with them \n",
    "# Then sort in ascending alphabetical order according to the management company names\n",
    "june15_subset = june15_df[june15_df['Address1'].str.contains('C/O', na=False)].sort_values(by='Address1')\n",
    "june15_subset['City'] = june15_subset['City'].str.title()\n",
    "june15_subset['Address1'] = june15_subset['Address1'].str.replace(r'\\bC/O\\b', '', regex=True).str.title()\n",
    "june15_subset['Address2'] = june15_subset['Address2'].str.title()\n",
    "june15_subset['Name'] = june15_subset['Name'].str.title()\n",
    "\n",
    "june15_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1bb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kept this the way it was (old, less accurate fuzzy) - see looping for correct code\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def singularize_word(word):\n",
    "    if len(word) > 3 and word.endswith('s') and not word.endswith('ss'):\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "def normalize_address(address):\n",
    "    if pd.isnull(address):\n",
    "        return ''\n",
    "    address = address.lower()\n",
    "    \n",
    "    # Normalize common road types\n",
    "    address = re.sub(r'\\b(streets|street|st)\\b', 'st', address)\n",
    "    address = re.sub(r'\\b(roads|road|rd)\\b', 'rd', address)\n",
    "    address = re.sub(r'\\b(avenues|avenue|ave)\\b', 'ave', address)\n",
    "    address = re.sub(r'\\b(boulevards|boulevard|blvd)\\b', 'blvd', address)\n",
    "    address = re.sub(r'\\b(suites|suite|ste|se)\\b', 'ste', address) \n",
    "    address = re.sub(r'\\b(apartments|apartment|apt)\\b', 'apt', address)\n",
    "    address = re.sub(r'\\b(forts|fort|ft)\\b', 'ft', address)\n",
    "    \n",
    "    # Standardize street directions\n",
    "    address = re.sub(r'\\b(south|s)\\b', 's', address)\n",
    "    address = re.sub(r'\\b(north|n)\\b', 'n', address)\n",
    "    address = re.sub(r'\\b(east|e)\\b', 'e', address)\n",
    "    address = re.sub(r'\\b(west|w)\\b', 'w', address)\n",
    "    address = re.sub(r'\\b(southeast|se)\\b', 'se', address)\n",
    "    address = re.sub(r'\\b(northeast|ne)\\b', 'ne', address)\n",
    "    address = re.sub(r'\\b(southwest|sw)\\b', 'sw', address)\n",
    "    address = re.sub(r'\\b(northwest|nw)\\b', 'nw', address)\n",
    "    \n",
    "    # Eliminate firm office indicators\n",
    "    address = re.split(r'\\b(suite|ste|apt|apartment|unit|site)\\b', address)[0]\n",
    "    \n",
    "    # Remove punctuation and number sign\n",
    "    address = re.sub(r'[.,]', '', address)\n",
    "    address = re.sub(r'\\s+', ' ', address).strip()\n",
    "    address = re.sub(r'#', '', address)\n",
    "\n",
    "    # Singularize words\n",
    "    address = ' '.join(singularize_word(word) for word in address.split())\n",
    "\n",
    "    return address\n",
    "\n",
    "# Do a similar process for the firm names\n",
    "def normalize_firm_name(name):\n",
    "    if pd.isnull(name):\n",
    "        return ''\n",
    "    name = name.lower().strip()\n",
    "    \n",
    "    # Remove suffixes\n",
    "    name = re.sub(r'\\b(llc|inc|corp|co|ltd)\\b', '', name)\n",
    "    \n",
    "    # Remove commas etc.\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    \n",
    "    # Singularize words\n",
    "    name = ' '.join(singularize_word(word) for word in name.split())\n",
    "    \n",
    "    return name\n",
    "\n",
    "# Normalize the phone\n",
    "def normalize_phone(phone):\n",
    "    if pd.isnull(phone):\n",
    "        return ''\n",
    "    return re.sub(r'\\D', '', str(phone))\n",
    "\n",
    "def get_mode(series):\n",
    "    mode = series.mode()\n",
    "    return mode.iloc[0] if not mode.empty else series.iloc[0]\n",
    "\n",
    "june15_subset['Address2_Normalized'] = june15_subset['Address2'].apply(normalize_address)\n",
    "june15_subset['Firm_Normalized'] = june15_subset['Address1'].apply(normalize_firm_name)\n",
    "june15_subset['Phone_Normalized'] = june15_subset['Telephone'].apply(normalize_phone)\n",
    "\n",
    "june15_subset['Firm_Normalized'] = june15_subset['Firm_Normalized'].str.replace(\n",
    "    r'\\bmangement\\b', 'management', regex=True\n",
    ")\n",
    "\n",
    "# Most common phone and address by firm name\n",
    "canonical_phone = (\n",
    "    june15_subset.groupby('Phone_Normalized')\n",
    "    .agg({'Firm_Normalized': get_mode})\n",
    "    .rename(columns={'Firm_Normalized': 'Firm_ByPhone'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "canonical_address = (\n",
    "    june15_subset.groupby('Address2_Normalized')\n",
    "    .agg({'Firm_Normalized': get_mode})\n",
    "    .rename(columns={'Firm_Normalized': 'Firm_ByAddress'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "june15_subset = june15_subset.merge(canonical_phone, on='Phone_Normalized', how='left')\n",
    "june15_subset = june15_subset.merge(canonical_address, on='Address2_Normalized', how='left')\n",
    "\n",
    "# Build the hierarchy\n",
    "def pick_canonical(row):\n",
    "    if pd.notnull(row['Firm_ByPhone']):\n",
    "        return row['Firm_ByPhone']\n",
    "    elif pd.notnull(row['Firm_ByAddress']):\n",
    "        return row['Firm_ByAddress']\n",
    "    else:\n",
    "        return row['Firm_Normalized']\n",
    "\n",
    "june15_subset['Firm_Canonical'] = june15_subset.apply(pick_canonical, axis=1)\n",
    "\n",
    "# Fuzzy matching within the canonical deduplication\n",
    "def fuzzy_within_group(group, threshold=90):\n",
    "    unique_names = group['Firm_Canonical'].unique()\n",
    "    name_map = {}\n",
    "    for name in unique_names:\n",
    "        if name in name_map:\n",
    "            continue\n",
    "        matches = process.extract(name, unique_names, scorer=fuzz.token_set_ratio, limit=None)\n",
    "        close_matches = [m[0] for m in matches if m[1] >= threshold]\n",
    "        for cm in close_matches:\n",
    "            name_map[cm] = name\n",
    "    group['Firm_Final'] = group['Firm_Canonical'].map(name_map).fillna(group['Firm_Canonical'])\n",
    "    return group\n",
    "\n",
    "# Apply fuzzy matching **within each phone group first** to avoid cross-company merges\n",
    "june15_subset = june15_subset.groupby('Phone_Normalized').apply(fuzzy_within_group).reset_index(drop=True)\n",
    "\n",
    "# Fuzzy across all names to catch edge cases\n",
    "all_names = june15_subset['Firm_Final'].unique()\n",
    "name_map_global = {}\n",
    "\n",
    "for name in all_names:\n",
    "    if name in name_map_global:\n",
    "        continue\n",
    "    matches = process.extract(name, all_names, scorer=fuzz.token_set_ratio, limit=None)\n",
    "    close_matches = [m[0] for m in matches if m[1] >= 90]  \n",
    "    for cm in close_matches:\n",
    "        name_map_global[cm] = name\n",
    "\n",
    "june15_subset['Firm_Final'] = june15_subset['Firm_Final'].map(name_map_global).fillna(june15_subset['Firm_Final'])\n",
    "\n",
    "# Save data\n",
    "june15_subset.to_csv('../Data/Cleaned files/june15_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in June 2025 data to make a complete set of data; get rid of associations that list condo in name and zero units cases\n",
    "\n",
    "june25_df = pd.read_excel(\"../Data/NRED/2025/NRED HOA - 06 2025.xlsx\")\n",
    "june25_df = june25_df[~june25_df['Name'].str.contains('condo', case=False, na=False)]\n",
    "june25_df = june25_df[~(june25_df['# of Units'] == 0)]\n",
    "\n",
    "june25_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16588f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another subset\n",
    "june25_subset = june25_df[june25_df['Address1'].str.contains('C/O', na=False)].sort_values(by='Address1')\n",
    "june25_subset['City'] = june25_subset['City'].str.title()\n",
    "june25_subset['Address1'] = june25_subset['Address1'].str.replace(r'\\bC/O\\b', '', regex=True).str.title()\n",
    "june25_subset['Address2'] = june25_subset['Address2'].str.title()\n",
    "june25_subset['Name'] = june25_subset['Name'].str.title()\n",
    "\n",
    "june25_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a50457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat process for second static period\n",
    "# Kept this the way it was (old, less accurate fuzzy) - see looping for correct code\n",
    "\n",
    "june25_subset['Address2_Normalized'] = june25_subset['Address2'].apply(normalize_address)\n",
    "june25_subset['Firm_Normalized'] = june25_subset['Address1'].apply(normalize_firm_name)\n",
    "june25_subset['Phone_Normalized'] = june25_subset['Telephone'].apply(normalize_phone)\n",
    "\n",
    "june25_subset['Firm_Normalized'] = june25_subset['Firm_Normalized'].str.replace(\n",
    "    r'\\bmangement\\b', 'management', regex=True\n",
    ")\n",
    "\n",
    "canonical_phone = (\n",
    "    june25_subset.groupby('Phone_Normalized')\n",
    "    .agg({'Firm_Normalized': get_mode})\n",
    "    .rename(columns={'Firm_Normalized': 'Firm_ByPhone'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "canonical_address = (\n",
    "    june25_subset.groupby('Address2_Normalized')\n",
    "    .agg({'Firm_Normalized': get_mode})\n",
    "    .rename(columns={'Firm_Normalized': 'Firm_ByAddress'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "june25_subset = june25_subset.merge(canonical_phone, on='Phone_Normalized', how='left')\n",
    "june25_subset = june25_subset.merge(canonical_address, on='Address2_Normalized', how='left')\n",
    "\n",
    "june25_subset['Firm_Canonical'] = june25_subset.apply(pick_canonical, axis=1)\n",
    "\n",
    "june25_subset = june25_subset.groupby('Phone_Normalized').apply(fuzzy_within_group).reset_index(drop=True)\n",
    "\n",
    "all_names = june25_subset['Firm_Final'].unique()\n",
    "name_map_global = {}\n",
    "\n",
    "for name in all_names:\n",
    "    if name in name_map_global:\n",
    "        continue\n",
    "    matches = process.extract(name, all_names, scorer=fuzz.token_set_ratio, limit=None)\n",
    "    close_matches = [m[0] for m in matches if m[1] >= 90] \n",
    "    for cm in close_matches:\n",
    "        name_map_global[cm] = name\n",
    "\n",
    "june25_subset['Firm_Final'] = june25_subset['Firm_Final'].map(name_map_global).fillna(june25_subset['Firm_Final'])\n",
    "\n",
    "june25_subset.to_csv('../Data/Cleaned files/june25_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd029e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyxlsb\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "nred_folder = '../Data/NRED/'\n",
    "\n",
    "# Find all Excel files within the folders\n",
    "all_files = glob.glob(os.path.join(nred_folder, '**', '*.xls*'), recursive=True)\n",
    "print(f\"Found {len(all_files)} Excel files\")\n",
    "\n",
    "# Create new list to store\n",
    "month_data = []\n",
    "\n",
    "for file in all_files:\n",
    "    try:\n",
    "        # Read Excel, handle .xlsb and .xls/.xlsx\n",
    "        if file.endswith('.xlsb'):\n",
    "            df = pd.read_excel(file, engine='pyxlsb')\n",
    "        else:\n",
    "            df = pd.read_excel(file)\n",
    "        \n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        # Try to extract month and year from file name (safer)\n",
    "        # Example file name: \"NRED HOA - 06 2015.xls\"\n",
    "        base_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        parts = base_name.split('-')[-1].strip().split()\n",
    "        if len(parts) != 2:\n",
    "            print(f\"Skipping {file}, cannot extract month/year\")\n",
    "            continue\n",
    "        month = int(parts[0])\n",
    "        year = int(parts[1])\n",
    "\n",
    "        # Filter out condos\n",
    "        df = df[~df['Name'].str.contains('condo', case=False, na=False)]\n",
    "\n",
    "        # Filter zero units using proper column name\n",
    "        if '# of Units' in df.columns:\n",
    "            df = df[df['# of Units'] > 0]\n",
    "\n",
    "        # Count total and professionally managed\n",
    "        total_rows = df.shape[0]\n",
    "        professional_rows = df['Address1'].str.contains('C/O', case=False, na=False).sum()\n",
    "\n",
    "        month_data.append({\n",
    "            'Year': year,\n",
    "            'Month': month,\n",
    "            'Total_HOAs': total_rows,\n",
    "            'Professional_HOAs': professional_rows\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "if not month_data:\n",
    "    raise ValueError(\"No valid files found to process!\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame(month_data)\n",
    "\n",
    "# Sort by Year and Month\n",
    "summary_df = summary_df.sort_values(['Year', 'Month']).reset_index(drop=True)\n",
    "\n",
    "# Save for Stata\n",
    "summary_df.to_csv('../Data/Misc/HOA_summary_monthly_for_stata.csv', index=False)\n",
    "print(\"Monthly summary CSV saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c02b406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 Excel files\n",
      "Processed ../Data/NRED\\2015\\NRED HOA - 06 2015.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2015\\NRED HOA - 07 2015.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2015\\NRED HOA - 08 2015.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2015\\NRED HOA - 09 2015.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2015\\NRED HOA - 10 2015.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2015\\NRED HOA - 11 2015.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2015\\NRED HOA - 12 2015.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 01 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 02 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 03 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 04 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 05 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 06 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 07 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 08 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 09 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 10 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 11 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2016\\NRED HOA - 12 2016.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 01 2017.xls -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 02 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 03 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 04 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 05 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 06 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 07 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 08 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 09 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 10 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 11 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2017\\NRED HOA - 12 2017.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 01 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 02 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 03 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 04 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 05 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 06 2018.xlsx -> subset + full versions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19548\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ../Data/NRED\\2018\\NRED HOA - 07 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 08 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 09 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 10 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 11 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2018\\NRED HOA - 12 2018.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 01 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 02 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 03 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 04 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 05 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 06 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 07 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 08 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 09 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 10 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 11 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2019\\NRED HOA - 12 2019.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 01 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 02 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 03 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 04 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 05 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 06 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 07 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 08 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 09 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 10 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 11 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2020\\NRED HOA - 12 2020.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 01 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 02 2021.xlsb -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 03 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 04 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 05 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 06 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 07 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 08 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 09 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 10 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 11 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2021\\NRED HOA - 12 2021.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 01 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 02 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 03 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 04 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 05 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 06 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 07 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 08 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 09 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 10 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 11 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2022\\NRED HOA - 12 2022.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 01 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 02 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 03 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 04 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 05 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 06 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 07 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 08 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 09 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 10 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 11 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2023\\NRED HOA - 12 2023.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 01 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 02 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 03 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 04 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 05 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 06 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 07 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 08 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 09 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 10 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 11 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2024\\NRED HOA - 12 2024.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2025\\NRED HOA - 01 2025.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2025\\NRED HOA - 02 2025.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2025\\NRED HOA - 03 2025.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2025\\NRED HOA - 04 2025.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2025\\NRED HOA - 05 2025.xlsx -> subset + full versions\n",
      "Processed ../Data/NRED\\2025\\NRED HOA - 06 2025.xlsx -> subset + full versions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "def singularize_word(word):\n",
    "    if len(word) > 3 and word.endswith('s') and not word.endswith('ss'):\n",
    "        return word[:-1]\n",
    "    return word\n",
    "\n",
    "def normalize_address(address):\n",
    "    if pd.isnull(address):\n",
    "        return ''\n",
    "    address = address.lower()\n",
    "    address = re.sub(r'\\b(streets|street|st)\\b', 'st', address)\n",
    "    address = re.sub(r'\\b(roads|road|rd)\\b', 'rd', address)\n",
    "    address = re.sub(r'\\b(avenues|avenue|ave)\\b', 'ave', address)\n",
    "    address = re.sub(r'\\b(boulevards|boulevard|blvd)\\b', 'blvd', address)\n",
    "    address = re.sub(r'\\b(suites|suite|ste|se)\\b', 'ste', address)\n",
    "    address = re.sub(r'\\b(apartments|apartment|apt)\\b', 'apt', address)\n",
    "    address = re.sub(r'\\b(forts|fort|ft)\\b', 'ft', address)\n",
    "    address = re.sub(r'\\b(south|s)\\b', 's', address)\n",
    "    address = re.sub(r'\\b(north|n)\\b', 'n', address)\n",
    "    address = re.sub(r'\\b(east|e)\\b', 'e', address)\n",
    "    address = re.sub(r'\\b(west|w)\\b', 'w', address)\n",
    "    address = re.sub(r'\\b(southeast|se)\\b', 'se', address)\n",
    "    address = re.sub(r'\\b(northeast|ne)\\b', 'ne', address)\n",
    "    address = re.sub(r'\\b(southwest|sw)\\b', 'sw', address)\n",
    "    address = re.sub(r'\\b(northwest|nw)\\b', 'nw', address)\n",
    "    address = re.split(r'\\b(suite|ste|apt|apartment|unit|site)\\b', address)[0]\n",
    "    address = re.sub(r'[.,]', '', address)\n",
    "    address = re.sub(r'#', '', address)\n",
    "    address = re.sub(r'\\s+', ' ', address).strip()\n",
    "    address = ' '.join(singularize_word(word) for word in address.split())\n",
    "    return address\n",
    "\n",
    "def normalize_firm_name(name):\n",
    "    if pd.isnull(name):\n",
    "        return ''\n",
    "    name = name.strip().lower()\n",
    "    name = re.sub(r'\\b(llc|inc|corp|corporation|co|company|ltd|limited)\\b', '', name)\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    name = ' '.join(singularize_word(word) for word in name.split())\n",
    "    return name\n",
    "\n",
    "def normalize_phone(phone):\n",
    "    if pd.isnull(phone):\n",
    "        return ''\n",
    "    phone_str = str(phone)\n",
    "    phone_str = re.split(r'[xX]', phone_str)[0]\n",
    "    return re.sub(r'\\D', '', phone_str)\n",
    "\n",
    "def get_mode(series):\n",
    "    mode = series.mode()\n",
    "    return min(mode, key=len) if not mode.empty else series.iloc[0]\n",
    "\n",
    "def pick_canonical(row):\n",
    "    if pd.notnull(row.get('Firm_ByPhone')):\n",
    "        return row['Firm_ByPhone']\n",
    "    elif pd.notnull(row.get('Firm_ByAddress')):\n",
    "        return row['Firm_ByAddress']\n",
    "    else:\n",
    "        return row.get('Firm_Normalized', '')\n",
    "\n",
    "root_folder = \"../Data/NRED/\"\n",
    "output_folder = \"../Data/Cleaned files/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "excel_files = glob.glob(os.path.join(root_folder, '**', '*.xls*'), recursive=True)\n",
    "print(f\"Found {len(excel_files)} Excel files\")\n",
    "\n",
    "for file in excel_files:\n",
    "    try:\n",
    "        df = pd.read_excel(file, dtype=str)\n",
    "\n",
    "        for col in ['Name', 'Address1', 'Address2', 'Telephone', 'City']:\n",
    "            if col in df.columns:\n",
    "                df[col] = (\n",
    "                    df[col].fillna('')\n",
    "                    .str.replace('\\xa0', ' ', regex=False)\n",
    "                    .str.strip()\n",
    "                    .str.replace(r'\\s+', ' ', regex=True)\n",
    "                )\n",
    "\n",
    "        df['Address1'] = df['Address1'].str.replace(\n",
    "            r'\\bP\\s*&\\s*G\\b.*', 'PANDG', flags=re.IGNORECASE, regex=True\n",
    "        )\n",
    "\n",
    "        # Filters\n",
    "        df = df[~df['Name'].str.contains('condo', case=False, na=False)]\n",
    "        df = df[df['# of Units'] != '0']\n",
    "\n",
    "        # Identify subset (professional management from C/O) and mask it\n",
    "        subset_mask = df['Address1'].str.contains('C/O', na=False)\n",
    "        subset = df[subset_mask].copy()\n",
    "\n",
    "        subset['City'] = subset['City'].str.title()\n",
    "        subset['Address1'] = subset['Address1'].str.replace(r'\\bC/O\\b', '', regex=True).str.title()\n",
    "        subset['Address2'] = subset['Address2'].str.title()\n",
    "        subset['Name'] = subset['Name'].str.title()\n",
    "\n",
    "        subset['Address2_Normalized'] = subset['Address2'].apply(normalize_address)\n",
    "        subset['Firm_Normalized'] = subset['Address1'].apply(normalize_firm_name)\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"ams mangement\", \"Firm_Normalized\"] = \"ams management group\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"firstservice residential\", \"Firm_Normalized\"] = \"firstservice residential nevada\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"first service residential\", \"Firm_Normalized\"] = \"firstservice residential nevada\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"level community management\", \"Firm_Normalized\"] = \"level property management\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"ccmc\", \"Firm_Normalized\"] = \"capital consultant management\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"seabeeze management\", \"Firm_Normalized\"] = \"seabreeze management\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"westward 360\", \"Firm_Normalized\"] = \"westward360\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"terra west property management\", \"Firm_Normalized\"] = \"terra west management service\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"nicklin community management\", \"Firm_Normalized\"] = \"nicklin community management service\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"nicklin property management\", \"Firm_Normalized\"] = \"nicklin community management service\"\n",
    "        subset.loc[subset[\"Firm_Normalized\"] == \"nicklin property management investment\", \"Firm_Normalized\"] = \"nicklin community management service\"\n",
    "        subset['Phone_Normalized'] = subset['Telephone'].apply(normalize_phone).replace('', pd.NA)\n",
    "\n",
    "        canonical_phone = subset.groupby('Phone_Normalized')['Firm_Normalized'].agg(get_mode).rename('Firm_ByPhone').reset_index()\n",
    "        canonical_address = subset.groupby('Address2_Normalized')['Firm_Normalized'].agg(get_mode).rename('Firm_ByAddress').reset_index()\n",
    "\n",
    "        subset = subset.merge(canonical_phone, on='Phone_Normalized', how='left')\n",
    "        subset = subset.merge(canonical_address, on='Address2_Normalized', how='left')\n",
    "        subset['Firm_Final'] = subset.apply(pick_canonical, axis=1)\n",
    "\n",
    "        firm_frequency = subset['Firm_Normalized'].value_counts()\n",
    "        STABLE_THRESHOLD = 10\n",
    "        def override_parent(row):\n",
    "            original = row['Firm_Normalized']\n",
    "            final = row['Firm_Final']\n",
    "            if original != final and firm_frequency.get(original, 0) >= STABLE_THRESHOLD:\n",
    "                return original\n",
    "            return final\n",
    "        subset['Firm_Final'] = subset.apply(override_parent, axis=1)\n",
    "        subset['Name_Changed_Flag'] = (subset['Firm_Normalized'] != subset['Firm_Final'])\n",
    "\n",
    "        base_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        subset.to_csv(os.path.join(output_folder, f\"{base_name}_subset.csv\"), index=False)\n",
    "\n",
    "        full_df = df.copy()\n",
    "\n",
    "        full_df.loc[subset_mask, 'Firm_Normalized'] = subset['Firm_Normalized']\n",
    "        full_df.loc[subset_mask, 'Firm_Final'] = subset['Firm_Final']\n",
    "        full_df.loc[subset_mask, 'Firm_ByPhone'] = subset['Firm_ByPhone']\n",
    "        full_df.loc[subset_mask, 'Firm_ByAddress'] = subset['Firm_ByAddress']\n",
    "        full_df.loc[subset_mask, 'Address2_Normalized'] = subset['Address2_Normalized']\n",
    "        full_df.loc[subset_mask, 'Name_Changed_Flag'] = subset['Name_Changed_Flag']\n",
    "\n",
    "        full_df.to_csv(os.path.join(output_folder, f\"{base_name}_full_plus_subset.csv\"), index=False)\n",
    "\n",
    "        print(f\"Processed {file} -> subset + full versions\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ce7355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 June subset CSV files\n",
      "Wide HOA dataset with Frequent changer and Number of changes saved to: ../Data/Cleaned files/HOA_Firm_Wide_Junes.csv\n",
      "Shape: (3235, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "input_folder = \"../Data/Cleaned files/\"\n",
    "output_file = os.path.join(input_folder, \"HOA_Firm_Wide_Junes.csv\")\n",
    "\n",
    "all_subset_files = glob.glob(os.path.join(input_folder, \"*_full_plus_subset.csv\"))\n",
    "\n",
    "csv_files = [f for f in all_subset_files if re.search(r'- 06 ', os.path.basename(f))]\n",
    "print(f\"Found {len(csv_files)} June subset CSV files\")\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    base_name = os.path.basename(file)\n",
    "    \n",
    "    year_search = re.search(r'(\\d{4})', base_name)\n",
    "    if year_search:\n",
    "        year = int(year_search.group(1))\n",
    "    else:\n",
    "        print(f\"Warning: Could not detect year from filename {base_name}, skipping\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(file, dtype=str)\n",
    "    \n",
    "    df = df[['Name', 'Firm_Final']].copy()\n",
    "\n",
    "    df['Name'] = df['Name'].str.strip().str.title()\n",
    "    \n",
    "    df['Year'] = year\n",
    "    \n",
    "    all_dfs.append(df)\n",
    "\n",
    "long_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "wide_df = long_df.pivot_table(\n",
    "    index='Name',\n",
    "    columns='Year',\n",
    "    values='Firm_Final',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "wide_df.columns.name = None\n",
    "\n",
    "wide_df_complete = wide_df.copy()\n",
    "\n",
    "year_columns = [col for col in wide_df_complete.columns if col != 'Name']\n",
    "\n",
    "def count_changes(row):\n",
    "    firms = row[year_columns].tolist()\n",
    "    changes = 0\n",
    "    for f1, f2 in zip(firms[:-1], firms[1:]):\n",
    "        # Only count as change if the two values are different\n",
    "        # and at least one of them is not NaN\n",
    "        if f1 != f2 and (pd.notna(f1) or pd.notna(f2)):\n",
    "            changes += 1\n",
    "    return changes\n",
    "\n",
    "wide_df_complete['Number of changes'] = wide_df_complete.apply(count_changes, axis=1)\n",
    "wide_df_complete['Frequent changer'] = wide_df_complete['Number of changes'] >= 2\n",
    "\n",
    "# Save output\n",
    "wide_df_complete.to_csv(output_file, index=False)\n",
    "print(f\"Wide HOA dataset with Frequent changer and Number of changes saved to: {output_file}\")\n",
    "print(\"Shape:\", wide_df_complete.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
